{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom random import randrange\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\nfrom csv import reader\nfrom math import sqrt\n \n# Load a CSV file\ndef load_csv(filename):\n    dataset = list()\n    with open(filename, 'r') as file:\n        csv_reader = reader(file)\n        for row in csv_reader:\n            noval=0\n            if not row:\n                continue\n            else:\n                cc = 0\n                for word in row:\n                    if (word):\n                        sword = str(word)\n                    else:\n                        noval =1\n                        break\n                    if (sword == '?'):\n                        noval=1\n                        break\n                    elif (cc == 1):\n                        if (sword == \"Federal-gov\"):\n                            row[cc] = 8\n                        elif (sword == \"Local-gov\"):\n                            row[cc] = 6\n                        elif(sword == \"Never-worked\"): \n                            row[cc] = 1\n                        elif(sword == \"Private\"):\n                            row[cc] = 5\n                        elif(sword == \"Self-emp-inc\"):\n                            row[cc] = 3\n                        elif(sword == \"Self-emp-not-inc\"): \n                            row[cc] = 4\n                        elif(sword == \"State-gov\"):\n                            row[cc] = 7\n                        elif(sword == \"Without-pay\"):\n                            row[cc] = 2\n                    elif (cc == 8):\n                        if (sword == \"Amer-Indian-Eskimo\"):\n                            row[cc] = 2\n                        elif (sword == \"Asian-Pac-Islander\"):\n                            row[cc] = 3\n                        elif (sword == \"Black\"):\n                            row[cc] = 1\n                        elif (sword == \"White\"):\n                            row[cc] = 4\n                        elif (sword == \"Other\"):\n                            row[cc] = 5\n                    elif(cc == 9):\n                        if (sword == \"Female\"):\n                            row[cc] = 0\n                        elif(sword == \"Male\"):\n                            row[cc] = 1\n                    elif (cc == 14):\n                        if (sword == \">50K\"):\n                            row[cc] = 1\n                        elif (sword == \"<=50K\"):\n                            row[cc] = 0\n                        else:\n                            noval = 1\n                            break\n                    else:\n                        word = None\n                    cc += 1\n                if (noval == 0):\n                    dataset.append(row)\n    return dataset\n\ndef drop_categorical_columns(dataset):\n    dset = list()\n    for row in dataset:\n        cc = 0\n        r = list()\n        for c in row:\n            if(cc == 2 or cc == 3 or cc == 5 or cc == 6 or cc == 7 or cc == 13):\n                cc += 1\n                continue\n            r.append(c)\n            cc += 1\n        dset.append(r)\n    return dset\n \n# Convert string column to integer\ndef str_column_to_int(dataset, column):\n    for row in dataset:\n        cc = 0\n        for c in row:\n            row[cc] = int(row[cc])\n            cc += 1\n    return dataset\n \n# Find the min and max values for each column\ndef dataset_minmax(dataset):\n\tminmax = list()\n\tfor i in range(len(dataset[0])):\n\t\tcol_values = [row[i] for row in dataset]\n\t\tvalue_min = min(col_values)\n\t\tvalue_max = max(col_values)\n\t\tminmax.append([value_min, value_max])\n\treturn minmax\n \n# Rescale dataset columns to the range 0-1\ndef normalize_dataset(dataset, minmax):\n\tfor row in dataset:\n\t\tfor i in range(len(row)):\n\t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n \n# Calculate the Euclidean distance between two vectors\ndef euclidean_distance(row1, row2):\n\tdistance = 0.0\n\tfor i in range(len(row1)-1):\n\t\tdistance += (row1[i] - row2[i])**2\n\treturn sqrt(distance)\n\ndef manhattan_distance(row1, row2): \n    _sum = 0\n    for i in range(len(row1)-1):\n        _sum += abs(row1[i] - row2[i])\n    return _sum\n\ndef jaccard_similarity(row1, row2):\n    r1 = []\n    r2 = []\n    for i in range(len(row1)-1):\n        r1.append(row1[i])\n    for i in range(len(row2)-1):\n        r2.append(row2[i])\n    intersection = len(list(set(r1).intersection(r2)))\n    union = (len(r1) + len(r2)) - intersection\n    return float(intersection) / union\n\n# Locate the most similar neighbors\ndef get_neighbors(train, test_row, num_neighbors):\n\tdistances = list()\n\tfor train_row in train:\n\t\tdist = jaccard_similarity(test_row, train_row)\n\t\tdistances.append((train_row, dist))\n\tdistances.sort(key=lambda tup: tup[1])\n\tneighbors = list()\n\tfor i in range(num_neighbors):\n\t\tneighbors.append(distances[i][0])\n\treturn neighbors\n \n# Split a dataset into k folds\ndef cross_validation_split(dataset, n_folds):\n\tdataset_split = list()\n\tdataset_copy = list(dataset)\n\tfold_size = int(len(dataset) / n_folds)\n\tfor _ in range(n_folds):\n\t\tfold = list()\n\t\twhile len(fold) < fold_size:\n\t\t\tindex = randrange(len(dataset_copy))\n\t\t\tfold.append(dataset_copy.pop(index))\n\t\tdataset_split.append(fold)\n\treturn dataset_split\n\n# Calculate accuracy percentage\ndef accuracy_metric(actual, predicted):\n\tcorrect = 0\n\tfor i in range(len(actual)):\n\t\tif actual[i] == predicted[i]:\n\t\t\tcorrect += 1\n\treturn correct / float(len(actual)) * 100.0\n    \n# Evaluate an algorithm using a cross validation split\ndef evaluate_algorithm(dataset, algorithm, n_folds, *args):\n\tfolds = cross_validation_split(dataset, n_folds)\n\tscores = list()\n\tfor fold in folds:\n\t\ttrain_set = list(folds)\n\t\ttrain_set.remove(fold)\n\t\ttrain_set = sum(train_set, [])\n\t\ttest_set = list()\n\t\tfor row in fold:\n\t\t\trow_copy = list(row)\n\t\t\ttest_set.append(row_copy)\n\t\t\trow_copy[-1] = None\n\t\tpredicted = algorithm(train_set, test_set, *args)\n\t\tactual = [row[-1] for row in fold]\n\t\taccuracy = accuracy_metric(actual, predicted)\n\t\tscores.append(accuracy)\n\treturn scores\n\n# kNN Algorithm\ndef k_nearest_neighbors(train, test, num_neighbors):\n\tpredictions = list()\n\tfor row in test:\n\t\toutput = predict_classification(train, row, num_neighbors)\n\t\tpredictions.append(output)\n\treturn(predictions)\n\n# Make a prediction with neighbors\ndef predict_classification(train, test_row, num_neighbors):\n\tneighbors = get_neighbors(train, test_row, num_neighbors)\n\toutput_values = [row[-1] for row in neighbors]\n\tprediction = max(set(output_values), key=output_values.count)\n\treturn prediction\n \n# Make a prediction with KNN on Iris Dataset\nfilename = '/kaggle/input/adult-census-income/adult.csv'\ndataset = load_csv(filename)\ndataset = drop_categorical_columns(dataset)\n\nfor i in range(len(dataset[0])):\n    str_column_to_int(dataset, i)\n\nnum_neighbors = 5\nn_folds = 5\n\n# predict the label\nscores = evaluate_algorithm(dataset, k_nearest_neighbors, n_folds, num_neighbors)\n\nprint('Scores: %s' % scores)\nprint('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}